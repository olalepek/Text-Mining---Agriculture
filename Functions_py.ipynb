{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPvi8VXKoehEIE8qyM75ED3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/olalepek/Text-Mining---Agriculture/blob/main/Functions_py.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Function definitions\n"
      ],
      "metadata": {
        "id": "vuep1bhXc73c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def pie_chart_characteristics_legend(characteristic, dataset):\n",
        "\n",
        "    filtered_df = dataset[dataset[characteristic].apply(lambda x: len(x) > 0)]\n",
        "    category_item = pd.Series([item for sublist in filtered_df[characteristic] for item in sublist])\n",
        "    category_counts = category_item.value_counts()\n",
        "    total = sum(category_counts)\n",
        "\n",
        "    plt.figure(figsize=(10, 7))\n",
        "    wedges, texts, autotexts = plt.pie(category_counts, labels=category_counts.index, startangle=140, autopct=\"\")\n",
        "\n",
        "    labels = [f'{label} - {count} ({(count/total)*100:.1f}%)' for label, count in zip(category_counts.index, category_counts)]\n",
        "\n",
        "    plt.title(f'{characteristic} Distribution')\n",
        "\n",
        "    plt.legend(wedges, labels, title=f'{characteristic} Summary', loc='center left', bbox_to_anchor=(1, 0.5))\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "ZJdbxhEGMtIv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_matches_for_characteristics (characteristic,excel,sheet,column1,column2,dataset):\n",
        "  xls = pd.ExcelFile(excel)\n",
        "  print(\"List of all sheets in the excel file loaded: \" + str(xls.sheet_names))\n",
        "  matches_df = pd.read_excel(excel, sheet_name=sheet)\n",
        "  characteristics = []\n",
        "  characteristics = matches_df.iloc[:, 0].tolist()\n",
        "  characteristics = [match.lower() for match in characteristics]\n",
        "  print(\"List of characteristics \" + str(characteristics))\n",
        "\n",
        "  nlp = spacy.load(\"en_core_web_sm\")\n",
        "  matcher = PhraseMatcher(nlp.vocab)\n",
        "  terms = characteristics\n",
        "  patterns = [nlp.make_doc(text) for text in terms]\n",
        "  matcher.add(\"TerminologyList\", patterns)\n",
        "\n",
        "  def find_matches(column1,column2):\n",
        "      text = column1 + \" \" + column2\n",
        "\n",
        "      doc = nlp(text)\n",
        "      matches = matcher(doc)\n",
        "      matched_terms = {doc[start:end].text for match_id, start, end in matches}\n",
        "      return list(matched_terms)\n",
        "\n",
        "  dataset[characteristic] =dataset.apply(lambda row: find_matches(row[column1], row[column2]), axis=1)\n",
        "\n",
        "  return dataset.head(1)"
      ],
      "metadata": {
        "id": "jwb3WdrVc-_N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pie_chart_characteristics (characteristic,dataset):\n",
        "  filtered_df = dataset[dataset[characteristic].apply(lambda x: len(x) > 0)]\n",
        "  filtered_df.info()\n",
        "\n",
        "  category_item = pd.Series([item for sublist in filtered_df[characteristic] for item in sublist])\n",
        "\n",
        "  category_counts = category_item.value_counts()\n",
        "\n",
        "  plt.figure(figsize=(10, 7))  # Adjust the size of the figure as needed\n",
        "  plt.pie(category_counts, labels=category_counts.index, autopct='%1.1f%%', startangle=140)\n",
        "  plt.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
        "\n",
        "  plt.title(characteristic + 'Distribution')\n",
        "\n",
        "  # Show the pie chart\n",
        "  return plt.show()"
      ],
      "metadata": {
        "id": "0IGwQdgGdCnP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def country_map(column,dataset):\n",
        "  category_item = pd.Series([item for sublist in dataset[column] for item in sublist])\n",
        "\n",
        "  country_counts = category_item.value_counts().reset_index()\n",
        "  country_counts.columns = ['Country', 'Counts']\n",
        "  fig = px.choropleth(country_counts,\n",
        "                    locations='Country',\n",
        "                    locationmode='country names',\n",
        "                    hover_name=\"Country\",\n",
        "                    hover_data={\"Counts\": True},\n",
        "                    color='Counts',\n",
        "                    color_continuous_scale=px.colors.sequential.Plasma,\n",
        "                    title='Country Counts')\n",
        "  return fig.show()\n"
      ],
      "metadata": {
        "id": "kbGBnlztdI1v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def patterns_from_excel (rules, rules_sheet):\n",
        "  rules_df = pd.read_excel(rules, sheet_name=rules_sheet)\n",
        "  rules_df.columns=[\"Label\", \"Pattern\"]\n",
        "  rules_pattern = [{\"label\": row[\"Label\"], \"pattern\": row[\"Pattern\"]} for index, row in rules_df.iterrows()]\n",
        "  print(\"list of patterns identified \")\n",
        "  return rules_pattern"
      ],
      "metadata": {
        "id": "7D9gZkNV4mJI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def set_entity_ruler (nlp, rules, rules_sheet, patterns, dataset, column_to_analyze,output_col_name):\n",
        "\n",
        "  rules_df = pd.read_excel(rules, sheet_name=rules_sheet)\n",
        "  rules_df.columns=[\"Label\", \"Pattern\"]\n",
        "  rules_pattern = [{\"label\": row[\"Label\"], \"pattern\": row[\"Pattern\"]} for index, row in rules_df.iterrows()]\n",
        "  print(\"list of patterns identified \" + str(patterns))\n",
        "  ruler = nlp.add_pipe(\"entity_ruler\", before = \"ner\")\n",
        "  ruler.add_patterns(rules_pattern)\n",
        "  ruler.add_patterns(patterns)\n",
        "\n",
        "  ruler_patterns = ruler.patterns\n",
        "\n",
        "  dataset[output_col_name] = dataset[column_to_analyze].apply(lambda text: [(ent.text, ent.label_) for ent in nlp(text).ents])\n",
        "\n",
        "\n",
        "  return dataset.head(1)"
      ],
      "metadata": {
        "id": "FNnYRr4Vf34e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def matcher(text):\n",
        "    doc = nlp(text)\n",
        "    matches = matcher(doc)\n",
        "    match_texts = []\n",
        "    for match_id, token_ids in matches:\n",
        "        match_text = ' '.join([doc[i].text for i in token_ids])\n",
        "        match_texts.append(match_text)\n",
        "    return match_texts\n"
      ],
      "metadata": {
        "id": "_vAblqDq8P3n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def regular_matcher(nlp, dataset, column_to_analyze, new_column, patterns, label):\n",
        "\n",
        "    matcher = Matcher(nlp.vocab)\n",
        "    for pattern_name, pattern in patterns.items():\n",
        "        matcher.add(pattern_name, [pattern])\n",
        "\n",
        "    def apply_matcher(text):\n",
        "        doc = nlp(text)\n",
        "        matches = matcher(doc)\n",
        "        return [doc[start:end].text for _, start, end in matches]\n",
        "\n",
        "    dataset[new_column] = dataset[column_to_analyze].apply(apply_matcher)\n",
        "    return dataset"
      ],
      "metadata": {
        "id": "atyeKpiNgN0Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def filter_label(entity_label_list, interested_labels):\n",
        "    unique_labels = {label for _, label in entity_label_list if label in interested_labels}\n",
        "    return list(unique_labels)\n",
        "\n"
      ],
      "metadata": {
        "id": "quYe0d9fN9gQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dependency_matcher(nlp, patterns, dataset, column_name_to_match, new_column):\n",
        "    matcher = DependencyMatcher(nlp.vocab)\n",
        "    for pattern_name, pattern in patterns.items():\n",
        "      matcher.add(\"Pattern\",[patterns])\n",
        "\n",
        "    def apply_matcher(text):\n",
        "        doc = nlp(text)\n",
        "        matches = matcher(doc)\n",
        "        match_texts = []\n",
        "        for match_id, token_ids in matches:\n",
        "            match_text = ' '.join(doc[i].text for i in token_ids)\n",
        "            match_texts.append(match_text)\n",
        "        return match_texts\n",
        "\n",
        "    dataset[new_column] = dataset[column_name_to_match].apply(apply_matcher)\n",
        "    return dataset.head(1)"
      ],
      "metadata": {
        "id": "GjPbkFhJjixU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def timeline_of_phrases_used_articles(dataframe, column_with_phrases, year_column, phrases_as_list):\n",
        "    df_list = []\n",
        "\n",
        "    for phrase in phrases_as_list:\n",
        "        mask = dataframe[column_with_phrases].str.contains(phrase, case=False, na=False)\n",
        "        df_filtered = dataframe[mask]\n",
        "        counts_per_year = df_filtered.groupby(year_column).size().reset_index(name='article_count')\n",
        "        counts_per_year['Term'] = phrase\n",
        "        df_list.append(counts_per_year)\n",
        "    combined_counts = pd.concat(df_list)\n",
        "\n",
        "    fig = px.line(combined_counts, x=year_column, y='article_count', color='Term',\n",
        "                  title='Article Count Over Years for Each Term',\n",
        "                  markers=True)\n",
        "\n",
        "    fig.update_layout(xaxis_title='Year', yaxis_title='Article Count', legend_title=\"Term\")\n",
        "    fig.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "a8J3YHcNLoGJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def count_values_non_empty_column(columns_of_interest, dataset):\n",
        "\n",
        "  unique_counts = {}\n",
        "  for column in columns_of_interest:\n",
        "      # Count non-empty lists in each column\n",
        "      non_empty_lists = dataset[column].apply(lambda x: len(x) > 0)\n",
        "      unique_counts[column] = non_empty_lists.sum()\n",
        "  return unique_counts\n"
      ],
      "metadata": {
        "id": "ODQ8cWCvcV0K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pie_chart_column_count (unique_counts, title):\n",
        "\n",
        "  labels = unique_counts.keys()\n",
        "  sizes = unique_counts.values()\n",
        "\n",
        "  # Plotting the pie chart\n",
        "  fig, ax = plt.subplots()\n",
        "  ax.pie(sizes, labels=labels, autopct='%1.1f%%', startangle=90)\n",
        "  ax.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
        "\n",
        "  # Display the pie chart\n",
        "  plt.title(title)\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "Qp1o2niReRu_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}